---
# title: "Identificaci√≥n de falseamiento ENUSC"
# author: "Marzo 2024"
format:
  revealjs:
    auto-stretch: false
    margin: 0
    slide-number: true
    scrollable: true
    preview-links: auto
    logo: imagenes/logo_portada2.png
    css: ine_quarto_styles.css
    # footer: <https://quarto.org>
---

#

[]{.linea-superior} 
[]{.linea-inferior} 

<!---
 <img src="imagenes/logo_portada2.png" style="width: 20%"/>  
--->

<img src="imagenes/logo_portada2.png" width="20%"/>  



[**Detecci√≥n de comportamientos an√≥malos en encuestas utilizando paradatos**]{.big-par .center-justified}
[**Proyecto Ciencia de Datos**]{.medium-par.center-justified}

[**Julio 2024**]{.big-par .center-justified}


## [Contenidos]{.big-par}  

<!-- ::: {.incremental} -->
- Motivaci√≥n üí°

- Flujo üë©‚Äçüíª üë®‚Äçüíª
  - [Esquema general]{.medium-par}
  - [Procesamiento de paradatos R]{.medium-par} 
  
- Monitoreo de comportamiento an√≥malo üîé
  - [Modelos predictivos ENUSC]{.medium-par}
  - [Dashboard de monitoreo]{.medium-par}
  
- Reflexi√≥n final ü§î

<!-- ::: -->



## [Motivaci√≥n (1/2)]{.big-par}

::: {.incremental .medium-par-2}

- El falseamiento es un problema que altera los resultados estad√≠sticos de una encuesta.

- Su detecci√≥n es dif√≠cil, por lo que suele hacerse una vez terminada la encuesta y con un consumo intensivo de recursos humanos.
  - Actualmente se supervisa aleatoriamente un 10% de las encuestas.
  
- Nace la necesidad de crear una herramienta que permita detectar el comportamiento an√≥malo en las entrevistas durante el levantamiento de la encuesta.

:::

## [Motivaci√≥n (2/2)]{.big-par}

¬øC√≥mo creamos esta herramienta? ü§î

::: {.incremental .medium-par-2}

- Procesando y analizando los datos que se van generando cuando las personas realizan alguna acci√≥n.
  - Es decir, procesar y analizar un gran volumen de informaci√≥n (paradatos) en *"tiempo real"* 

- Con esto, podemos ayudar al equipo de supervisi√≥n dirigiendo los casos en donde existan comportamientos fuera de lo normal. 
  
:::


## [Flujo | Esquema general]{.big-par}

::: {.incremental .medium-par-2}

- El flujo ETL (Extracci√≥n, Transformaci√≥n, Carga) es implementado usando el orquestador Dagster. üë®‚Äçüíªüßâ

  [<img src="imagenes/dagster_etl_enusc_tech_pres_01.png"/>]{.center} 


:::

## [Flujo | Procesamiento de paradatos (1/6)]{.big-par}

**¬øQu√© son los paradatos?**

<!-- introducir muy a grandes rasgos sus caracteristicas para despues entrar en detalle en como se procesaron los datos para que quedaran a nivel de entrevista -->

::: {.incremental .medium-par}
- Los paradatos son todos los registros brutos de cada acci√≥n que se realiza en las entrevistas.
  
  :::{.small-par-2}
  
  ```{r paradatos_brutos, echo= FALSE}
  
  library(RPresto)
  library(DBI)
  library(dplyr)
  library(kableExtra)
  
  con.trino <- DBI::dbConnect(
    RPresto::Presto(),
    use.trino.headers = TRUE,
    host = "10.90.10.60",
    port = 8080,
    user = "root",
    catalog = "hive",
    schema = "staging"
  )
  
  
  paradato_bruto <- dbGetQuery(con.trino, 'SELECT * FROM "staging".enusc_paradatos_raw_2023  LIMIT 7')
  
  paradato_bruto %>% select(-order_number) %>% kbl()
  
  ```
  :::


- Durante el levantamiento de ENUSC 2023 se alcanzaron un total de *66.375.084* observaciones aproximadamente.

:::


## [Flujo | Procesamiento de paradatos (2/6)]{.big-par}


::: {.incremental .medium-par}

- Pero no todos los eventos registrados son de inter√©s. 

- En el an√°lisis s√≥lo necesitamos las acciones realizadas por los responsables de la encuesta (encuestadores y encargados de grupo).

- Estas acciones consisten en los siguientes eventos reportados como:   
  - **AnswerSet**, **AnswerRemoved**, **CommentSet**, **OpenedBySupervisor**, **RejectedBySupervisor**, **ApproveBySupervisor**, **Completed**
  
:::


```{r elim_conexion, echo=FALSE, message= FALSE, warning=FALSE, include=FALSE}
query_3 = '
          SELECT event
          , count(*) as event_count
          FROM "staging".enusc_paradatos_raw
          GROUP BY event
          ORDER BY event_count DESC
          '

aux <- dbGetQuery(con.trino, query_3) %>% 
  rename(Eventos = event,
         Cantidad = event_count) 

```

:::: {layout-ncol=2}

::: {.fragment .small-par .center}

```{r tabla_eventos1, echo=FALSE}
aux %>% slice(1:13) %>% kbl() %>% row_spec(c(3, 8, 11, 13), background = 'lightyellow1')
```

:::

::: {.fragment .small-par .center}

```{r tabla_eventos2, echo=FALSE}
aux %>% slice(14:26) %>% kbl() %>% row_spec(c(4, 8, 9), background = 'lightyellow1')
```

::: 

::::

<br>

## [Flujo | Procesamiento de paradatos (3/6)]{.big-par}

```{r ejemplo_respuestas, echo = FALSE}

library(dplyr)
library(kableExtra)

load('data/tabla_ejemplo_tiempos.RData')
aux$interview_id <- '11111'
aux <- aux %>% 
  slice(5:11) %>% 
  mutate(role = '1',
         tiempo_desfasado = lag(timestamp_utc_TZ)) %>% 
  mutate(Diferencia_tiempo = timestamp_utc_TZ- tiempo_desfasado) %>% 
  select(-preguntas_com, -tiempo_desfasado, -diff_respuesta) 

```



**¬øC√≥mo se realiza la estimaci√≥n de la cantidad de eventos?**

:::{.incremental .medium-par}
1. Para cada entrevista, realizamos un conteo de eventos registrados seg√∫n responsable (encuestador o encargado de grupo)

2. Este conteo se realiza para: *AnswerSet*, *AnswerRemoved*, *CommentSet*, *OpenedBySupervisor*, *RejectedBySupervisor*, *ApproveBySupervisor*, *Completed*
:::

. . .

Ejemplo:


::::{layout-ncol=2}

:::{.fragment .small-par-2 .center}

```{r ejemplo_cantidad_respuestas1, echo = FALSE}
aux %>% 
  select(-Diferencia_tiempo, -timestamp_utc_TZ) %>% 
  kbl()

```

:::

:::{.fragment .small-par .center}


```{r ejemplo_cantidad_respuestas2, echo = FALSE}

aux %>%
  select(-Diferencia_tiempo, -timestamp_utc_TZ) %>% 
  group_by(interview_id, role, event) %>% 
  summarise(Cantidad = n()) %>% 
  kbl()

```

:::

::::

## [Flujo | Procesamiento de paradatos (4/6)]{.big-par}


 <!-- - Si el tiempo es mayor a 3 minutos para encuestadores o mayor a 15 minutos para encargados de grupos, se eliminar√° pues es considerado como punto de inicio de otra visita/ revisi√≥n realizada. -->

. . .

**¬øC√≥mo se realiza la estimaci√≥n de los tiempos de respuesta?**

:::{.incremental .medium-par}

1. Para cada entrevista, se ordena seg√∫n el tiempo en que se registran los eventos.

2. Calculamos la diferencia de tiempo entre eventos consecutivos.
    
    - Si la diferencia de tiempo es mayor al umbral definido para cada responsable, esta ser√° eliminada pues es considerado como punto de inicio de otra visita o revisi√≥n.

:::
    
. . .

Ejemplo:

:::{.small-par}

```{r ejemplo_tiempos_respuesta}
aux %>% 
  kbl() %>% 
    row_spec(4,
           background = 'lightyellow1')

```



:::

. . .

Tiempo total acciones: `r aux %>% filter(Diferencia_tiempo<180) %>% pull(Diferencia_tiempo) %>% sum()`


## [Flujo | Procesamiento de paradatos (5/6)]{.big-par}

**¬øC√≥mo se estima los tiempos de respuesta en las diferentes secciones (m√≥dulos)?**

:::{.incremental .medium-par}

1. Al igual que en el caso anterior, ordenaremos seg√∫n el tiempo de registro de eventos

2. Calculamos la diferencia de tiempo entre eventos consecutivos, pero tomaremos como tiempo inicial cuando se registre la fecha de inicio de cada secci√≥n:

    [<img src="imagenes/plots/todas_las_secciones.PNG" width="60%"/>]{.center} 
:::


## [Flujo | Procesamiento de paradatos (6/6)]{.big-par}

Ejemplo de tabla procesada que resume las acciones generadas en cada entrevista:

:::{.small-par-2}

```{r head_resumen_interview, echo = FALSE}

resumen_head <- dbGetQuery(con.trino, 
                           'SELECT interview_id, time_answer_interviewer, time_answer_supervisor, 
                                   n_answer_interviewer, n_completed_interviewer, n_commentset_interviewer,
                                   n_rejected_supervisor,
                                   reg_cdf
                            FROM "staging".enusc_paradatos_trans_interviews
                            LIMIT 4')

resumen_head$interview_id <- 1000000:1000003

resumen_head[, 1:4] %>% kbl()
```

<br>

```{r head_resumen_interview2, echo = FALSE}
resumen_head[, c(1, 5:8)] %>% kbl()

```


:::

```{r disconect, echo = FALSE, message=FALSE, include=FALSE}
dbDisconnect(con.trino)
```



## [Monitoreo de comportamiento]{.big-par}

:::{.incremental .medium-par}

- Para identificar comportamientos anormales, se realiz√≥ un dashboard de monitoreo para las encuestas *ENUSC* y *ENPCCL*.

- El cual consta de diferentes pesta√±as, en donde se analiza el **comportamiento de registro de respuestas** de los encuestadores y encargados de grupo.

- Para la ENUSC, se crearon modelos predictivos los cuales nos ayudan en esta tarea de detecci√≥n de anomal√≠as.

:::


## [Monitoreo de comportamiento | Modelos predictivos ENUSC (1/4)]{.big-par}

:::{.incremental .medium-par}

- Para identificar comportamientos an√≥malos, utilizaremos la informaci√≥n **a nivel de entrevista**, es decir, en una fila existe informaci√≥n de una entrevista (interview_id).

- Trabajaremos con los casos en que la entrevista haya sido realizada en el dispositivo ***DMC*** (se omiten entrevistas realizadas en papel o por tel√©fono) y tengan un estado final ***completa*** o ***falseada*** (CDF 11 o 45).

- En total, contamos con *50.159* observaciones, las cuales se distribuyen como:

    | | Proporci√≥n*|
    |---|---|
    | **Encuesta normal** | 97.35% |
    | **Encuesta falseada** | 2.64% |
    
    
    [* *se incluye informaci√≥n de sectores que tuvieron que ser reencuestados por casos de falsificaci√≥n*]{.small-par}
:::


## [Monitoreo de comportamiento | Modelos predictivos ENUSC (2/4)]{.big-par}

::: {.incremental .medium-par}

- Dada la naturaleza desbalanceada de los datos, se decidi√≥ usar dos metodolog√≠as de *machine learning* para identificar el comportamiento an√≥malo en las entrevistas:

  1. Modelo XGBoost (supervisado)
  
  2. Modelo K-means (no supervisado)

- Para ello, se utilizaron 15 variables:
  
  - Tiempo de respuesta (4)
  - Cantidad de respuestas (6)
  - Acciones de encargado de grupo (3)
  - Acciones encuestador (1)
  - Visitas encuestador (1)

:::

## [Monitoreo de comportamiento | Modelos predictivos ENUSC (3/4)]{.big-par}

::::{layout-ncol=2}

:::{.fragment .incremental}

[1. **Modelo XGBoost**]{.big-par}

<br>

```{r echo =FALSE, warning=FALSE, message=FALSE, fig.align='center'}
library(dplyr)
library(kableExtra)
library(readxl)

table_xgb <- read_excel('data/confusion_matrix_XGBOOST.xlsx')
metricas_xgb <- read_excel('data/metricas_XGBOOST.xlsx')

```


**Matriz de confusi√≥n (set de testeo):**

::: {.medium-par}

  | | Predicci√≥n XGB| 
  |---|---|---|
  | **Caso an√≥malo**| No | Si |
  | No | `r pull(table_xgb[1,2])` | `r pull(table_xgb[2,2])` |
  | Si | `r pull(table_xgb[1,3])` | `r pull(table_xgb[2,3])` |
:::

<br>

**M√©tricas (set de testeo):**

::: {.medium-par}

| |  | 
|---|---|
| Tasa de predicci√≥n positiva | `r round(pull(table_xgb[2,3])/(pull(table_xgb[2,3]) + pull(table_xgb[1,3])), 4)`|
| F1 | `r round(2*((pull(table_xgb[2,3])/(pull(table_xgb[2,3])+pull(table_xgb[2,2])))*(pull(table_xgb[2,3])/(pull(table_xgb[2,3])+pull(table_xgb[1,3]))))/((pull(table_xgb[2,3])/(pull(table_xgb[2,3])+pull(table_xgb[2,2])))+(pull(table_xgb[2,3])/(pull(table_xgb[2,3])+pull(table_xgb[1,3])))),4)` |
| Exactitud (accuracy)| `r round(pull(metricas_xgb[3, 2]), 4)` |

:::

::: 

:::{.fragment .incremental}


[2. **Modelo K-means**]{.big-par}

<br>

**Matriz de confusi√≥n (set de testeo):**

```{r echo =FALSE, warning=FALSE, message=FALSE, fig.align='center'}

table_km <- read_excel('data/confusion_matrix_KMEANS.xlsx')
metricas_km <- read_excel('data/metricas_KMEANS.xlsx')

```


::: {.medium-par}
  | | Predicci√≥n Kmeans| 
  |---|---|---|
| **Caso an√≥malo**| No | Si |
| No | `r pull(table_km[1,2])` | `r pull(table_km[2,2])`|
| Si | `r pull(table_km[1,3])` | `r pull(table_km[2,3])`|

:::

<br>

**M√©tricas (set de testeo):**

::: {.medium-par}


| |  | 
|---|---|
| Tasa de predicci√≥n positiva | `r round(pull(table_km[2,3])/(pull(table_km[2,3]) + pull(table_km[1,3])), 4)`|
| F1 | `r round(2*((pull(table_km[2,3])/(pull(table_km[2,3])+pull(table_km[2,2])))*(pull(table_km[2,3])/(pull(table_km[2,3])+pull(table_km[1,3]))))/((pull(table_km[2,3])/(pull(table_km[2,3])+pull(table_km[2,2])))+(pull(table_km[2,3])/(pull(table_km[2,3])+pull(table_km[1,3])))), 4)`|
| Exactitud (accuracy)| `r  round(pull(metricas_km[3, 2]), 4)`|

:::

:::

::::

## [Monitoreo de comportamiento | Modelos predictivos ENUSC (4/4)]{.big-par}

```{r seleccion_aleatoria, echo =FALSE, warning=FALSE, message=FALSE, fig.align='center'}
set.seed(10)

predicciones <- read_excel('data/predicciones_python.xlsx') %>% select(-`...1`)

index_al <- sample(1:nrow(predicciones ), nrow(predicciones )*0.1)
aux <- predicciones [index_al, ] %>% 
  pull(valor_real) %>% table 
aux1 =  aux %>% prop.table() %>% round(digits = 4) *100

```


::: {.medium-par .incremental}

- Quiz√°s las m√©tricas alcanzadas no son las mejores, pero recordemos que la metodolog√≠a actual de supervisi√≥n consiste en realizar una muestra aleatoria del 10% del total de entrevistas.

- Por ejemplo, seleccionemos aleatoriamente el 10% de nuestro set de testeo (seleccionamos y supervisamos `r aux[1] + aux[2]` observaciones):

    | **Comportamiento an√≥malo**| n| Proporci√≥n |
    |---|---|---|
    | **No** | `r aux[1]`| `r aux1[1]` % |
    | **Si** | `r aux[2]`| `r aux1[2]` % |
      
    [*$^*$Casos an√≥malos que quedan fuera `r table(predicciones$valor_real)[2] - aux[2]` *]{.small-par .center}

:::



## [Monitoreo de comportamiento | Dashboard de monitoreo (1/5)]{.big-par}

:::{.incremental .medium-par}

- Para la creaci√≥n del dashboard, se utiliz√≥ *streamlit*

- Streamlit nos permite crear una app interactiva desde python, sin la necesidad de tener conocimiento de *back* y *front* *end*, lo que la hace bastante intuitiva
  - Pero puede ser un arma de doble filo si no se es ordenado con el c√≥digo üòµ!

- Para los dashboards de monitoreo, se cre√≥ una app *multipage*, es decir, que posee diferentes pesta√±as:
  
    <img src="imagenes/plots/dashboard_multipage.png" width="90%"/>
    
:::


## [Monitoreo de comportamiento | Dashboard de monitoreo (2/5)]{.big-par}

:::{.incremental .medium-par}

- Lo cual se hace simplemente dejando un script principal y creando la carpeta *pages*, en donde estar√°n los dem√°s scripts:

  [<img src="imagenes/plots/orden_carpetas.png" width="30%"/>]{.center} 
  
- El n√∫mero que aparece en el nombre del script, indica el orden de aparici√≥n en el dashboard.

- Dentro de cada script, esta todo el c√≥digo que usaremos en aquella pesta√±a, sin la necesidad tener la estructura UI-Server.
  
:::

## [Monitoreo de comportamiento | Dashboard de monitoreo (3/5)]{.big-par}

:::{.incremental .medium-par}

- En Shiny, esto se veria como:

  - UI:   
    [<img src="imagenes/plots/shiny1.png"/>]{.center} 
  
  - Server:
    [<img src="imagenes/plots/shiny2.png"/>]{.center} 
:::


## [Monitoreo de comportamiento | Dashboard de monitoreo (4/5)]{.big-par}

. . .

Mucho blah blah üò¥...

. . .

¬øQue nos muestra el dashboard? üïµÔ∏è‚Äç‚ôÄÔ∏è

. . .

:::{.incremental .medium-par}

- El dashboard posee 5 pesta√±as, 1 de login y 4 de an√°lisis de paradatos.

- Ambas encuestas (ENUSC y ENPCCL), poseen las pesta√±as:

  - **General**: Vista general de la cantidad y tiempos de respuesta 
  - **Revisi√≥n Encuestador**: An√°lisis del comportamiento de respuesta del encuestador ¬øCuanto se demora en promedio en realizar las encuestas semanalmente o diariamente? ¬øCuantas entrevistas realiza? ¬ø Ha agregado comentarios?
  - **Revisi√≥n Encargado de grupo**: De forma similar a la pesta√±a *Revisi√≥n Encuestador*, se analiza el comportamiento de revisi√≥n de los encargados de grupo.

:::

## [Monitoreo de comportamiento | Dashboard de monitoreo (5/5)]{.big-par}

:::{.incremental .medium-par}
- Para la **ENUSC**, podemos encontrar una pesta√±a de *Revisi√≥n modelo*, en donde se realiza una predicci√≥n con los modelos ajustados, siempre y cuando las entrevistas cumplan con los supuestos (CDF = 11, realizaci√≥n en DMC) y se analizan los resultados alcanzados.

- Para la **ENPCCL**, tenemos una pesta√±a con *rankings* para evaluar el comportamiento de respuesta seg√∫n ciertos indicadores de inter√©s del equipo.

:::

<br>

. . .

[¬°Vamos al dashboard üöÄ! [link](http://10.90.10.60:8010/)]{.center .big-par}

. . .

## [Reflexi√≥n final]{.big-par}

:::{.incremental .medium-par}
- A trav√©s del *machine learning*, buscamos ayudar a identificar casos con comportamiento an√≥malo en la encuesta, complementando el trabajo del equipo de supervisi√≥n.

- Actualmente, estamos preparando un servicio experimental para la ENUSC 2024 y ENPCCL 2024.

- Si el servicio funciona con √©xito, se evaluar√° extender la metodolog√≠a a otras encuestas.

- Pr√≥ximos pasos
  
  - Seguiremos trabajando para afinar las predicciones alcanzadas, buscando nuevas variables de interes.
  
  - En un futuro, nos gustar√≠a poder implementar una identificaci√≥n de perfiles de encuestadores por ej 'el encuestador buena onda', 'el madrugador', etc.

:::


# 


[]{.linea-superior} 
[]{.linea-inferior} 



<!---
 <img src="imagenes/logo_portada2.png" style="width: 20%"/>  
--->

<img src="imagenes/logo_portada2.png" width="20%"/>  

[**Detecci√≥n de comportamientos an√≥malos en encuestas utilizando paradatos**]{.big-par .center-justified}
[**Proyecto Ciencia de Datos**]{.medium-par.center-justified}

[**Julio 2024**]{.big-par .center-justified}


